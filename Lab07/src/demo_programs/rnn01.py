import numpy as np
from keras.layers import SimpleRNN

inputs = np.random.random([32, 10, 8]).astype(np.float32)
print("Inputs: ")
print(inputs)

simple_rnn = SimpleRNN(4)

output = simple_rnn(inputs)  # The output has shape `[32, 4]`.
print("Output: ")
print(output)

simple_rnn = SimpleRNN(
    4, return_sequences=True, return_state=True)

# whole_sequence_output has shape `[32, 10, 4]`.
# final_state has shape `[32, 4]`.
whole_sequence_output, final_state = simple_rnn(inputs)

# Inputs: 
# [[[0.18161975 0.20779175 0.8761127  ... 0.22742668 0.05824969 0.2767511 ]
#   [0.57508117 0.62144387 0.17314641 ... 0.49315727 0.50228393 0.26218963]
#   [0.83730763 0.0475235  0.06679165 ... 0.7901113  0.1633005  0.16079047]
#   ...
#   [0.06835925 0.6572572  0.65966165 ... 0.6399464  0.48645085 0.4857361 ]
#   [0.11025329 0.36614117 0.28357896 ... 0.71490926 0.7010059  0.07368352]
#   [0.16531189 0.82797074 0.9948384  ... 0.49112776 0.59628016 0.57427853]]

#  [[0.34973487 0.05927771 0.50314367 ... 0.19381477 0.41875216 0.65671843]
#   [0.507008   0.22750717 0.9777507  ... 0.6535325  0.5693632  0.570547  ]
#   [0.19686545 0.7950833  0.5902164  ... 0.92777973 0.40379727 0.6414291 ]
#   ...
#   [0.41243076 0.99156773 0.3570208  ... 0.07638378 0.72985685 0.87025166]
#   [0.79528296 0.24944483 0.7815656  ... 0.5830099  0.6609365  0.7573211 ]
#   [0.03535173 0.99984735 0.8768539  ... 0.40887928 0.36204556 0.38267624]]

#  [[0.6697391  0.12372094 0.37262872 ... 0.01169182 0.611028   0.86824244]
#   [0.26889494 0.2511642  0.24365933 ... 0.2846499  0.90768653 0.8786754 ]
#   [0.11333723 0.6055385  0.05711789 ... 0.67102677 0.43509078 0.97210723]
#   ...
#   [0.58377296 0.5964474  0.7767739  ... 0.20241468 0.39065772 0.99475306]
#   [0.8737478  0.33514917 0.97779024 ... 0.94890946 0.5165388  0.18210645]
#   [0.6943603  0.88795197 0.41326773 ... 0.01692715 0.3938328  0.17595853]]

#  ...

#  [[0.89248896 0.92110276 0.9446325  ... 0.3640865  0.7251439  0.05537419]
#   [0.6877885  0.30601636 0.80147165 ... 0.2430434  0.75524056 0.46790192]
#   [0.04096546 0.3044238  0.8545969  ... 0.03736401 0.78478754 0.59555805]
#   ...
#   [0.3456036  0.6950731  0.3406043  ... 0.2835172  0.8091515  0.9928103 ]
#   [0.7938438  0.04722132 0.14327796 ... 0.53049314 0.8084564  0.11877944]
#   [0.24672073 0.9135747  0.09388091 ... 0.63292795 0.25686678 0.7425665 ]]

#  [[0.21463837 0.10374688 0.20477705 ... 0.3965682  0.8286978  0.7590355 ]
#   [0.7962062  0.6493054  0.26241547 ... 0.16305105 0.17183724 0.41495416]
#   [0.98076105 0.7788616  0.32026187 ... 0.08552735 0.6489797  0.6145593 ]
#   ...
#   [0.14928634 0.897777   0.9433825  ... 0.2418008  0.38069105 0.22230363]
#   [0.8619632  0.32452005 0.30535126 ... 0.2856328  0.8154572  0.42992517]
#   [0.63348943 0.57546383 0.86637336 ... 0.54720587 0.3340328  0.98053706]]

#  [[0.10579832 0.19024074 0.5410295  ... 0.98659825 0.18850772 0.9622199 ]
#   [0.5537349  0.4928328  0.98431337 ... 0.819717   0.51856786 0.14737411]
#   [0.71622413 0.49057165 0.57103854 ... 0.19510855 0.5780639  0.14746286]
#   ...
#   [0.04479926 0.20973438 0.33093494 ... 0.30558115 0.8844267  0.10278481]
#   [0.05385715 0.8200758  0.54425156 ... 0.5012816  0.4637413  0.644691  ]
#   [0.19205217 0.31859708 0.62324345 ... 0.15038693 0.8770115  0.5463585 ]]]
# 2024-05-13 14:38:09.529011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
# To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
# Output: 
# tf.Tensor(
# [[-0.24250238  0.9113273   0.13588841  0.8027335 ]
#  [-0.83311015  0.9734107  -0.27461556  0.7648091 ]
#  [-0.25455815  0.91271514 -0.5890482   0.39444143]
#  [-0.01550478  0.8494129  -0.0967754   0.61866814]
#  [-0.46507767  0.7978432   0.40043578  0.6276618 ]
#  [-0.19944358  0.9844862  -0.44856757  0.7196012 ]
#  [-0.5147727   0.91212624 -0.11082502  0.31185946]
#  [-0.3349964   0.95763564  0.6338453   0.77447945]
#  [-0.51060236  0.874358   -0.1089181   0.6513719 ]
#  [-0.46934912  0.9335998  -0.03754037  0.80756307]
#  [-0.16402957  0.78729427 -0.17435764  0.37696707]
#  [ 0.06583425  0.97888124 -0.624171    0.7154197 ]
#  [-0.79593796  0.8826434  -0.25439397  0.30275452]
#  [-0.7974053   0.9627457  -0.05185832  0.66753477]
#  [ 0.23696896  0.96334237  0.83423245  0.7400863 ]
#  [-0.70696783  0.90814424  0.4556504   0.9133928 ]
#  [-0.4648706   0.7877033  -0.2873415   0.40088618]
#  [-0.7370874   0.89177173  0.02085248  0.82536995]
#  [-0.6210199   0.90955067 -0.50679815  0.14245526]
#  [-0.8749652   0.78652626 -0.03874531  0.13775018]
#  [ 0.02163883  0.9208236  -0.03846127  0.76123357]
#  [ 0.25658813  0.90526    -0.48269492  0.1966562 ]
#  [-0.3610005   0.7308551  -0.3243623   0.5180711 ]
#  [ 0.35856643  0.9895974  -0.6421621   0.83826   ]
#  [ 0.25698587  0.93008304  0.5714918   0.7169107 ]
#  [-0.6831131   0.9484186   0.55198544  0.17578797]
#  [-0.33206427  0.96656424  0.29840815  0.27303147]
#  [-0.05698163  0.91518545  0.1872878   0.6961911 ]
#  [-0.6778372   0.76329124 -0.12966086  0.6863307 ]
#  [-0.57787544  0.94728845  0.63062376  0.7614075 ]
#  [-0.45828977  0.8306908  -0.03827843  0.6530204 ]
#  [-0.3036714   0.963608    0.36364844  0.29133818]], shape=(32, 4), dtype=float32)